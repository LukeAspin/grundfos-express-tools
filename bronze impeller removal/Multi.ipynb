{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from openpyxl import load_workbook,worksheet,Workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MYDIR= r\"C:\\Projects\\2022\\Michaels_Code\\grundfos-express-tools\\bronze impeller removal\\input files\"\n",
    "OUTPUT_DIR=r\"C:\\Projects\\2022\\Michaels_Code\\grundfos-express-tools\\bronze impeller removal\\output files\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PNs to be Removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_pns = [\n",
    "    96699290, 97775274, 96699299, 97775277, 96778078,\n",
    "    97780992, 96699305, 96769184, 97778033, 96769190,\n",
    "    96769205, 97778039, 96769256, 96896891, 96769259,\n",
    "    96769271, 97780970, 96769280, 97780973\n",
    "]\n",
    "\n",
    "str_list = [str(numstr) for numstr in list_of_pns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justification Note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_removal_note():\n",
    "    timeStamp = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "    reason = input(\"Reason for removal: \")\n",
    "    authority = input(\"Who authorized/requested this change? \")\n",
    "    return timeStamp + \" \" + reason + \" per \" + authority\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geeting the First Row of the PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb=load_workbook(r'C:\\Projects\\2022\\Michaels_Code\\grundfos-express-tools\\bronze impeller removal\\input files\\Lbom-ES.xlsx',read_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_row(wb:Workbook,sheet_name:str,min_row:int=None,max_row:int=None,min_col:int=None,max_col:int=None):\n",
    "    try:\n",
    "        if not sheet_name in wb.sheetnames:\n",
    "            raise Exception\n",
    "        ws=wb[sheet_name]\n",
    "    except:\n",
    "        print('Sheet does not exist')\n",
    "    min_col = min_col or 1\n",
    "    min_row = min_row or 1\n",
    "    max_col = max_col or ws.max_column\n",
    "    max_row = max_row or ws.max_row\n",
    "    for row in ws.iter_rows(min_row,max_row,min_col,max_col):\n",
    "        if row[0].value=='[START]':\n",
    "            return row[0].row-1\n",
    "\n",
    "psd_startrow=get_start_row(wb,'Impeller',min_row=1,max_col=1)\n",
    "psd_startcol=0\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_then_separate_by(psd_data:DataFrame,list_of_cols: list, pn_col: str)->tuple[DataFrame,DataFrame]:\n",
    "    \"\"\"list of cols are grouping categories. pn_col is the column that contains pns to find matches on.\"\"\"\n",
    "    groups = psd_data.groupby(list_of_cols) # Had to play around with this to get the right groupings\n",
    "\n",
    "    df_list_to_remove = [] # will hold list of dataframes to be removed. Will concatenate to 1 dataframe later\n",
    "    df_list_to_keep   = [] # will hold list of dataframes to remain in PSD. Will concatenate to 1 dataframe later\n",
    "\n",
    "    # Iterates through each sub-group, checking if there is a pn that meets criteria for removal\n",
    "    for _, frame in groups:\n",
    "        if any(frame[pn_col].isin(str_list)):   # Finding matching partnumbers to remove\n",
    "            df_list_to_remove.append(frame)     # Need to add this sub-group to a \"removed dataframe\"\n",
    "        else:\n",
    "            df_list_to_keep.append(frame)       # Need to retain this sub-group, add to a \"keep dataframe\"\n",
    "\n",
    "    # Concatenating list of dfs to single dfs.\n",
    "    removals = pd.concat(df_list_to_remove)\n",
    "    keep = pd.concat(df_list_to_keep)\n",
    "        \n",
    "    return removals, keep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate Through Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from typing import Callable,Any,ParamSpec,TypeVar,Concatenate\n",
    "from _utils.file_ops import read_files_in_dir\n",
    "from _utils.Dataframe_tools import get_df\n",
    "\n",
    "P = ParamSpec('P')\n",
    "\n",
    "######## START HERE #####\n",
    "#Workbook contains Sheets and each file contains only one workbook therefore each file contains multiple sheets\n",
    "#We want to make a list for any given file of the sheets we want to process \n",
    "#We can take a single sheet and process over it with the below function\n",
    "\n",
    "def process_sheet(sheet):\n",
    "    pass\n",
    "\n",
    "#If we want to process multiple sheets within a file we need to loop over an iterable of the sheets we want and we can define this as a sepertate function.\n",
    "\n",
    "def process_file(file,sheets):\n",
    "    for sheet in sheets:\n",
    "        process_sheet()\n",
    "\n",
    "#I need to process each of the files in my directory \n",
    "def process_dir(dir):\n",
    "    pass\n",
    "\n",
    "files=read_files_in_dir(MYDIR)\n",
    "sheetname='Impeller'\n",
    "\n",
    "\n",
    "for file in files:\n",
    "    removal_note=add_removal_note()\n",
    "    data,fname=file\n",
    "    psd_data=pd.read_excel(data,sheet_name=sheetname,header=psd_startrow-1,dtype={'BOM':str})\n",
    "    original_psd_bottom_row = len(psd_data) + psd_startrow\n",
    "    print(\"Opening file for updates: {}\".format(os.path.basename(fname)))\n",
    "    end_row = psd_data[psd_data['Full Data'] == '[END]'].index.to_list()[0]\n",
    "    psd_data = psd_data.iloc[:end_row]\n",
    "    group_by_columns = [\"Model\", \"Price ID\"]\n",
    "    removals, keep = group_then_separate_by(psd_data,group_by_columns, \"BOM\")\n",
    "    removals.loc[removals[\"Full Data\"] == \"[START]\", \"Full Data\"] = \"\"\n",
    "    new_row = pd.DataFrame({'ID': removal_note}, index =[0])\n",
    "    removals = pd.concat([new_row, removals[:]]).reset_index()\n",
    "    column_list = keep.columns\n",
    "    removals = removals[column_list]\n",
    "    removals.sort_values(by=['ID'], inplace=True)\n",
    "    keep.loc[0,'Full Data'] = np.nan\n",
    "    keep.sort_values(by=['ID'], inplace=True)\n",
    "    keep.reset_index(drop=True, inplace=True)\n",
    "    keep.loc[0,'Full Data'] = \"[START]\"\n",
    "    num_rows = len(keep)                         \n",
    "    keep.loc[num_rows,'Full Data']=\"[END]\"\n",
    "\n",
    "\n",
    "#Assuming only one sheet for right now\n",
    "# def before_change_data(dir,sheet_name:list[list[str]],is_same_note=True):\n",
    "#     files=read_files_in_dir(dir)\n",
    "#     for i,file in files:\n",
    "#         sheet=[]\n",
    "#         note=add_removal_note()\n",
    "#         for sheet in sheet_name[i]:\n",
    "#             sheet.append({'header':get_start_row(load_workbook(file[0],read_only=True),sheet_name=sheet,min_row=1,max_col=1)})\n",
    "#             if not is_same_note:\n",
    "#                 note=add_removal_note()\n",
    "            \n",
    "# before_change_data()\n",
    "\n",
    "\n",
    "# a=list(before_change_data(MYDIR))\n",
    "\n",
    "\n",
    "# def change_data(file:tuple[bytes,str,str],psd_data_func:Callable[Concatenate[P],DataFrame],psd_data_args:tuple[list,dict]):\n",
    "#     removal_note=add_removal_note()\n",
    "#     data,fname=file\n",
    "#     psd_data=psd_data_func(data,*psd_data_args[0]) #will have to be called as a list or all have to be the same\n",
    "#     original_psd_bottom_row = len(psd_data) + psd_startrow\n",
    "#     print(\"Opening file for updates: {}\".format(os.path.basename(fname)))\n",
    "#     #...This is where the real processing begins...\n",
    "#     end_row = psd_data[psd_data['Full Data'] == '[END]'].index.to_list()[0]\n",
    "#     psd_data = psd_data.iloc[:end_row]\n",
    "#     group_by_columns = [\"Model\", \"Price ID\"]\n",
    "#     removals, keep = group_then_separate_by(psd_data,group_by_columns, \"BOM\")\n",
    "#     removals.loc[removals[\"Full Data\"] == \"[START]\", \"Full Data\"] = np.nan\n",
    "#     new_row = pd.DataFrame({'ID': removal_note}, index =[0])\n",
    "#     removals = pd.concat([new_row, removals[:]]).reset_index()\n",
    "#     column_list = keep.columns\n",
    "#     removals = removals[column_list]\n",
    "#     removals.sort_values(by=['ID'], inplace=True)\n",
    "#     keep.loc[0,'Full Data'] = np.nan\n",
    "#     keep.sort_values(by=['ID'], inplace=True)\n",
    "#     keep.reset_index(drop=True, inplace=True)\n",
    "#     keep.loc[0,'Full Data'] = \"[START]\"\n",
    "#     return keep,removals,fname\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for Misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (len(keep[keep['BOM'].isin(str_list)])) == 0:\n",
    "    print(\"Didn't miss any partnumbers. Good to go\")\n",
    "else:\n",
    "    print(\"For some reason, the following entries were missed\")\n",
    "    print(keep[keep['BOM'].isin(str_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows=len(keep)\n",
    "append_location = original_psd_bottom_row - len(removals) \n",
    "after_end_row = num_rows + psd_startrow + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return a formatted file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl.styles import PatternFill\n",
    "\n",
    "outputPath=r'C:\\Projects\\2022\\Michaels_Code\\grundfos-express-tools\\bronze impeller removal\\output files\\Revised Lbom-ES.xlsx'\n",
    "\n",
    "wb = load_workbook(outputPath)\n",
    "ws = wb['Impeller']\n",
    "tabName = sheetname + \" No Bronze\"\n",
    "wb.copy_worksheet(ws).title = tabName\n",
    "ws_modified = wb[tabName]\n",
    "ws_modified.delete_rows(after_end_row, len(removals)-1)\n",
    "end_cell=ws.cell(row=after_end_row-1,column=1)\n",
    "end_cell.fill=PatternFill(fill_type='solid',bgColor=\"FFCC99\")\n",
    "for rows in ws_modified.iter_rows(min_row=append_location+2, max_row=append_location+2, min_col=1, max_col=40):\n",
    "    for cell in rows:\n",
    "        cell.fill = PatternFill(start_color=\"FF0000\", end_color=\"FF0000\", fill_type=\"solid\")\n",
    "wb.save(outputPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making New File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from _utils.excel_tools import write_excel_file\n",
    "from _utils.file_ops import add_str_to_filename\n",
    "from _utils.Dataframe_tools import write_df_to_excel\n",
    "\n",
    "\n",
    "write_df_to_excel(keep,outputPath,tabName,startrow=psd_startrow-1,startcol=psd_startcol)\n",
    "write_df_to_excel(removals,outputPath,tabName,header=False, startrow=append_location+1, startcol=psd_startcol)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d89935b22884bac8e846ef6a5fb14ff565b7e382ac92ebe1031401d4b8e3f29"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
