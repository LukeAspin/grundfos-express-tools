{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from openpyxl import load_workbook,worksheet,Workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MYDIR= r\"C:\\Projects\\2022\\Michaels_Code\\grundfos-express-tools\\bronze impeller removal\\input files\"\n",
    "OUTPUT_DIR=r\"C:\\Projects\\2022\\Michaels_Code\\grundfos-express-tools\\bronze impeller removal\\output files\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PNs to be Removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_pns = [\n",
    "    96699290, 97775274, 96699299, 97775277, 96778078,\n",
    "    97780992, 96699305, 96769184, 97778033, 96769190,\n",
    "    96769205, 97778039, 96769256, 96896891, 96769259,\n",
    "    96769271, 97780970, 96769280, 97780973\n",
    "]\n",
    "\n",
    "str_list = [str(numstr) for numstr in list_of_pns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justification Note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_removal_note():\n",
    "    timeStamp = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "    reason = input(\"Reason for removal: \")\n",
    "    authority = input(\"Who authorized/requested this change? \")\n",
    "    return timeStamp + \" \" + reason + \" per \" + authority\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geeting the First Row of the PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb=load_workbook(r'C:\\Projects\\2022\\Michaels_Code\\grundfos-express-tools\\bronze impeller removal\\input files\\Lbom-ES.xlsx',read_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_row(wb:Workbook,sheet_name:str,min_row:int=None,max_row:int=None,min_col:int=None,max_col:int=None):\n",
    "    try:\n",
    "        if not sheet_name in wb.sheetnames:\n",
    "            raise Exception\n",
    "        ws=wb[sheet_name]\n",
    "    except:\n",
    "        print('Sheet does not exist')\n",
    "    min_col = min_col or 1\n",
    "    min_row = min_row or 1\n",
    "    max_col = max_col or ws.max_column\n",
    "    max_row = max_row or ws.max_row\n",
    "    for row in ws.iter_rows(min_row,max_row,min_col,max_col):\n",
    "        if row[0].value=='[START]':\n",
    "            return row[0].row-1\n",
    "\n",
    "psd_startrow=get_start_row(wb,'Impeller',min_row=1,max_col=1)\n",
    "psd_startcol=0\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_then_separate_by(psd_data:DataFrame,list_of_cols: list, pn_col: str)->tuple[DataFrame,DataFrame]:\n",
    "    \"\"\"list of cols are grouping categories. pn_col is the column that contains pns to find matches on.\"\"\"\n",
    "    groups = psd_data.groupby(list_of_cols) # Had to play around with this to get the right groupings\n",
    "\n",
    "    df_list_to_remove = [] # will hold list of dataframes to be removed. Will concatenate to 1 dataframe later\n",
    "    df_list_to_keep   = [] # will hold list of dataframes to remain in PSD. Will concatenate to 1 dataframe later\n",
    "\n",
    "    # Iterates through each sub-group, checking if there is a pn that meets criteria for removal\n",
    "    for _, frame in groups:\n",
    "        if any(frame[pn_col].isin(str_list)):   # Finding matching partnumbers to remove\n",
    "            df_list_to_remove.append(frame)     # Need to add this sub-group to a \"removed dataframe\"\n",
    "        else:\n",
    "            df_list_to_keep.append(frame)       # Need to retain this sub-group, add to a \"keep dataframe\"\n",
    "\n",
    "    # Concatenating list of dfs to single dfs.\n",
    "    removals = pd.concat(df_list_to_remove)\n",
    "    keep = pd.concat(df_list_to_keep)\n",
    "        \n",
    "    return removals, keep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate Through Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from typing import Callable,Any,ParamSpec,TypeVar,Concatenate\n",
    "from utils.file_ops import read_files_in_dir\n",
    "\n",
    "\n",
    "P = ParamSpec('P')\n",
    "\n",
    "######## START HERE #####\n",
    "#Workbook contains Sheets and each file contains only one workbook therefore each file contains multiple sheets\n",
    "#We want to make a list for any given file of the sheets we want to process \n",
    "#We can take a single sheet and process over it with the below function\n",
    "\n",
    "\n",
    "\n",
    "files=read_files_in_dir(MYDIR)\n",
    "sheetname='Impeller'\n",
    "\n",
    "\n",
    "for file in files:\n",
    "    removal_note=add_removal_note()\n",
    "    data,fname=file\n",
    "    psd_data=pd.read_excel(data,sheet_name=sheetname,header=psd_startrow-1,dtype={'BOM':str})\n",
    "    original_psd_bottom_row = len(psd_data) + psd_startrow\n",
    "    \n",
    "    print(\"Opening file for updates: {}\".format(os.path.basename(fname)))\n",
    "    end_row = psd_data[psd_data['Full Data'] == '[END]'].index.to_list()[0]\n",
    "    psd_data = psd_data.iloc[:end_row]\n",
    "    group_by_columns = [\"Model\", \"Price ID\"]\n",
    "    removals, keep = group_then_separate_by(psd_data,group_by_columns, \"BOM\")\n",
    "    removals.loc[removals[\"Full Data\"] == \"[START]\", \"Full Data\"] = \"\"\n",
    "    new_row = pd.DataFrame({'ID': removal_note}, index =[0])\n",
    "    removals = pd.concat([new_row, removals[:]]).reset_index()\n",
    "    column_list = keep.columns\n",
    "    removals = removals[column_list]\n",
    "    removals.sort_values(by=['ID'], inplace=True)\n",
    "    keep.loc[0,'Full Data'] = np.nan\n",
    "    keep.sort_values(by=['ID'], inplace=True)\n",
    "    keep.reset_index(drop=True, inplace=True)\n",
    "    keep.loc[0,'Full Data'] = \"[START]\"\n",
    "    num_rows = len(keep)                      \n",
    "    keep.loc[num_rows,'Full Data']=\"[END]\"\n",
    "    append_location = original_psd_bottom_row - len(removals) \n",
    "    after_end_row = num_rows + psd_startrow + 2\n",
    "\n",
    "\n",
    "#Assuming only one sheet for right now\n",
    "# def before_change_data(dir,sheet_name:list[list[str]],is_same_note=True):\n",
    "#     files=read_files_in_dir(dir)\n",
    "#     for i,file in files:\n",
    "#         sheet=[]\n",
    "#         note=add_removal_note()\n",
    "#         for sheet in sheet_name[i]:\n",
    "#             sheet.append({'header':get_start_row(load_workbook(file[0],read_only=True),sheet_name=sheet,min_row=1,max_col=1)})\n",
    "#             if not is_same_note:\n",
    "#                 note=add_removal_note()\n",
    "            \n",
    "# before_change_data()\n",
    "\n",
    "\n",
    "# a=list(before_change_data(MYDIR))\n",
    "\n",
    "\n",
    "# def change_data(file:tuple[bytes,str,str],psd_data_func:Callable[Concatenate[P],DataFrame],psd_data_args:tuple[list,dict]):\n",
    "#     removal_note=add_removal_note()\n",
    "#     data,fname=file\n",
    "#     psd_data=psd_data_func(data,*psd_data_args[0]) #will have to be called as a list or all have to be the same\n",
    "#     original_psd_bottom_row = len(psd_data) + psd_startrow\n",
    "#     print(\"Opening file for updates: {}\".format(os.path.basename(fname)))\n",
    "#     #...This is where the real processing begins...\n",
    "#     end_row = psd_data[psd_data['Full Data'] == '[END]'].index.to_list()[0]\n",
    "#     psd_data = psd_data.iloc[:end_row]\n",
    "#     group_by_columns = [\"Model\", \"Price ID\"]\n",
    "#     removals, keep = group_then_separate_by(psd_data,group_by_columns, \"BOM\")\n",
    "#     removals.loc[removals[\"Full Data\"] == \"[START]\", \"Full Data\"] = np.nan\n",
    "#     new_row = pd.DataFrame({'ID': removal_note}, index =[0])\n",
    "#     removals = pd.concat([new_row, removals[:]]).reset_index()\n",
    "#     column_list = keep.columns\n",
    "#     removals = removals[column_list]\n",
    "#     removals.sort_values(by=['ID'], inplace=True)\n",
    "#     keep.loc[0,'Full Data'] = np.nan\n",
    "#     keep.sort_values(by=['ID'], inplace=True)\n",
    "#     keep.reset_index(drop=True, inplace=True)\n",
    "#     keep.loc[0,'Full Data'] = \"[START]\"\n",
    "#     return keep,removals,fname\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for Misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (len(keep[keep['BOM'].isin(str_list)])) == 0:\n",
    "    print(\"Didn't miss any partnumbers. Good to go\")\n",
    "else:\n",
    "    print(\"For some reason, the following entries were missed\")\n",
    "    print(keep[keep['BOM'].isin(str_list)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return a formatted file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl.styles import PatternFill\n",
    "\n",
    "outputPath=r'C:\\Projects\\2022\\Michaels_Code\\grundfos-express-tools\\bronze impeller removal\\output files\\Revised Lbom-ES.xlsx'\n",
    "\n",
    "# wb = load_workbook(outputPath)\n",
    "# ws = wb['Impeller']\n",
    "# tabName = sheetname + \" No Bronze\"\n",
    "# wb.copy_worksheet(ws).title = tabName\n",
    "# ws_modified = wb[tabName]\n",
    "# ws_modified.delete_rows(after_end_row, len(removals)-1)\n",
    "# end_cell=ws.cell(row=after_end_row-1,column=1)\n",
    "# end_cell.fill=PatternFill(fill_type='solid',start_color=\"FFCC99\",end_color=\"FFCC99\")\n",
    "# for rows in ws_modified.iter_rows(min_row=append_location+2, max_row=append_location+2, min_col=1, max_col=40):\n",
    "#     for cell in rows:\n",
    "#         cell.fill = PatternFill(start_color=\"FF0000\", end_color=\"FF0000\", fill_type=\"solid\")\n",
    "# wb.save(outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputPath=r'C:\\Projects\\2022\\Michaels_Code\\grundfos-express-tools\\bronze impeller removal\\output files\\Revised Lbom-ES.xlsx'\n",
    "# tabName = sheetname + \" No Bronze\"\n",
    "\n",
    "# with pd.ExcelWriter(outputPath, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:  \n",
    "#             keep.to_excel(writer, sheet_name=tabName, index=False, startrow=psd_startrow-1, startcol=psd_startcol)\n",
    "#             removals.to_excel(writer, sheet_name=tabName, index=False, header=False, startrow=append_location+1, startcol=psd_startcol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.read_excel(outputPath,'Impeller',header=None)\n",
    "# header=df.loc[:4,:]\n",
    "# rest=df.loc[5:,:]\n",
    "# rest.reset_index(drop=True, inplace=True)\n",
    "# rest.columns=rest.loc[0,:]\n",
    "# rest=rest.drop(0)\n",
    "# from typing import overload,Literal,Sequence,Hashable,Iterable,Callable\n",
    "# from pandas._typing import DtypeArg,StorageOptions\n",
    "# from pandas.util._decorators import Appender\n",
    "\n",
    "\n",
    "outputPath=r'C:\\Projects\\2022\\Michaels_Code\\grundfos-express-tools\\bronze impeller removal\\output files\\Revised Lbom-ES.xlsx'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def _find_header_end(df:DataFrame)->int:\n",
    "#     for row in df.itertuples():\n",
    "#         if row[1]=='[START]':\n",
    "#             return int(row[0])\n",
    "\n",
    "\n",
    "# @overload\n",
    "# def _get_df(\n",
    "#     io,\n",
    "#     # sheet name is str or int -> DataFrame\n",
    "#     sheet_name: str | int,\n",
    "#     header: int | Sequence[int] | None = ...,\n",
    "#     names=...,\n",
    "#     index_col: int | Sequence[int] | None = ...,\n",
    "#     usecols=...,\n",
    "#     squeeze: bool | None = ...,\n",
    "#     dtype: DtypeArg | None = ...,\n",
    "#     engine: Literal[\"xlrd\", \"openpyxl\", \"odf\", \"pyxlsb\"] | None = ...,\n",
    "#     converters=...,\n",
    "#     true_values: Iterable[Hashable] | None = ...,\n",
    "#     false_values: Iterable[Hashable] | None = ...,\n",
    "#     skiprows: Sequence[int] | int | Callable[[int], object] | None = ...,\n",
    "#     nrows: int | None = ...,\n",
    "#     na_values=...,\n",
    "#     keep_default_na: bool = ...,\n",
    "#     na_filter: bool = ...,\n",
    "#     verbose: bool = ...,\n",
    "#     parse_dates=...,\n",
    "#     date_parser=...,\n",
    "#     thousands: str | None = ...,\n",
    "#     decimal: str = ...,\n",
    "#     comment: str | None = ...,\n",
    "#     skipfooter: int = ...,\n",
    "#     convert_float: bool | None = ...,\n",
    "#     mangle_dupe_cols: bool = ...,\n",
    "#     storage_options: StorageOptions = ...,\n",
    "# ) -> tuple[DataFrame,DataFrame,int]:\n",
    "#     ...\n",
    "\n",
    "\n",
    "# @Appender(pd.read_excel.__doc__,join='\\n')\n",
    "# def _get_df(**kwargs):\n",
    "#     \"\"\"This extends the pandas read_excel method for our uses.\n",
    "#     Params:\n",
    "#     **kwargs: Takes in keyword arguments only. These arguments also inherit from the \n",
    "#     \"\"\"\n",
    "#     df=pd.read_excel(**kwargs) #Reading the dataframe\n",
    "#     header_size=_find_header_end(df) #Getting the size of the header\n",
    "\n",
    "#     #Need to get the other dataframes\n",
    "#     psd_df=df.loc[header_size-1:,:]\n",
    "#     psd_df.reset_index(drop=True,inplace=True)\n",
    "#     psd_df.columns=psd_df.loc[0,:]\n",
    "#     psd_df=psd_df.drop(0)\n",
    "#     original_length=len(df)\n",
    "\n",
    "#     #Lets Check if we are using the header df\n",
    "#     if bool(kwargs.get('use_header',False)):\n",
    "#         if kwargs['use_header']==True:\n",
    "#             header=df.loc[:header_size-2,:]\n",
    "#             return header,psd_df,original_length\n",
    "#         else:\n",
    "#             return psd_df,original_length\n",
    "#     return psd_df,original_length\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening file for updates: Lbom-ES.xlsx\n",
      "Closing file: Lbom-ES.xlsx \n",
      " Wrote file: Revised Lbom-ES.xlsx to C:\\Projects\\2022\\Michaels_Code\\grundfos-express-tools\\bronze impeller removal\\output files\n",
      "Opening file for updates: LCS-bom-ES.xlsx\n",
      "Closing file: LCS-bom-ES.xlsx \n",
      " Wrote file: Revised LCS-bom-ES.xlsx to C:\\Projects\\2022\\Michaels_Code\\grundfos-express-tools\\bronze impeller removal\\output files\n",
      "Opening file for updates: LFE_bom-ES.xlsx\n",
      "Closing file: LFE_bom-ES.xlsx \n",
      " Wrote file: Revised LFE_bom-ES.xlsx to C:\\Projects\\2022\\Michaels_Code\\grundfos-express-tools\\bronze impeller removal\\output files\n",
      "Opening file for updates: VL-VLSbom.xlsx\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Grouper for 'Model' not 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Projects\\2022\\Michaels_Code\\grundfos-express-tools\\bronze impeller removal\\Multi.ipynb Cell 23'\u001b[0m in \u001b[0;36m<cell line: 181>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Projects/2022/Michaels_Code/grundfos-express-tools/bronze%20impeller%20removal/Multi.ipynb#ch0000022?line=178'>179</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mClosing file: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(file_name)),\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWrote file: \u001b[39m\u001b[39m{\u001b[39;00mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(outPut_file_path)\u001b[39m}\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m{\u001b[39;00mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(outPut_file_path)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Projects/2022/Michaels_Code/grundfos-express-tools/bronze%20impeller%20removal/Multi.ipynb#ch0000022?line=180'>181</a>\u001b[0m \u001b[39mfor\u001b[39;00m task \u001b[39min\u001b[39;00m tasks:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Projects/2022/Michaels_Code/grundfos-express-tools/bronze%20impeller%20removal/Multi.ipynb#ch0000022?line=181'>182</a>\u001b[0m     write_new_PSD(\u001b[39m*\u001b[39;49mtask)\n",
      "\u001b[1;32mc:\\Projects\\2022\\Michaels_Code\\grundfos-express-tools\\bronze impeller removal\\Multi.ipynb Cell 23'\u001b[0m in \u001b[0;36mwrite_new_PSD\u001b[1;34m(file_name, psd_data, grouping_func, length, removal_note, sheet_name, outPut_file_path)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Projects/2022/Michaels_Code/grundfos-express-tools/bronze%20impeller%20removal/Multi.ipynb#ch0000022?line=143'>144</a>\u001b[0m end_row \u001b[39m=\u001b[39m psd_data[psd_data[\u001b[39m'\u001b[39m\u001b[39mFull Data\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m[END]\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mto_list()[\u001b[39m0\u001b[39m]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Projects/2022/Michaels_Code/grundfos-express-tools/bronze%20impeller%20removal/Multi.ipynb#ch0000022?line=144'>145</a>\u001b[0m psd_data \u001b[39m=\u001b[39m psd_data\u001b[39m.\u001b[39miloc[:end_row]\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Projects/2022/Michaels_Code/grundfos-express-tools/bronze%20impeller%20removal/Multi.ipynb#ch0000022?line=145'>146</a>\u001b[0m removals, keep \u001b[39m=\u001b[39m grouping_func[\u001b[39m0\u001b[39m](psd_data,\u001b[39m*\u001b[39mgrouping_func[\u001b[39m1\u001b[39m],\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mgrouping_func[\u001b[39m2\u001b[39m])\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Projects/2022/Michaels_Code/grundfos-express-tools/bronze%20impeller%20removal/Multi.ipynb#ch0000022?line=146'>147</a>\u001b[0m removals\u001b[39m.\u001b[39mloc[removals[\u001b[39m\"\u001b[39m\u001b[39mFull Data\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m[START]\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFull Data\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Projects/2022/Michaels_Code/grundfos-express-tools/bronze%20impeller%20removal/Multi.ipynb#ch0000022?line=147'>148</a>\u001b[0m new_row \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m'\u001b[39m\u001b[39mID\u001b[39m\u001b[39m'\u001b[39m: removal_note}, index \u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m])\n",
      "\u001b[1;32mc:\\Projects\\2022\\Michaels_Code\\grundfos-express-tools\\bronze impeller removal\\Multi.ipynb Cell 23'\u001b[0m in \u001b[0;36mgroup_then_separate_by\u001b[1;34m(psd_data, list_of_cols, pn_col, str_list)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/2022/Michaels_Code/grundfos-express-tools/bronze%20impeller%20removal/Multi.ipynb#ch0000022?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgroup_then_separate_by\u001b[39m(psd_data:DataFrame,list_of_cols: \u001b[39mlist\u001b[39m, pn_col: \u001b[39mstr\u001b[39m, str_list:\u001b[39mlist\u001b[39m[\u001b[39mstr\u001b[39m])\u001b[39m-\u001b[39m\u001b[39m>\u001b[39m\u001b[39mtuple\u001b[39m[DataFrame,DataFrame]:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/2022/Michaels_Code/grundfos-express-tools/bronze%20impeller%20removal/Multi.ipynb#ch0000022?line=25'>26</a>\u001b[0m     \u001b[39m\"\"\"list of cols are grouping categories. pn_col is the column that contains pns to find matches on.\"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Projects/2022/Michaels_Code/grundfos-express-tools/bronze%20impeller%20removal/Multi.ipynb#ch0000022?line=26'>27</a>\u001b[0m     groups \u001b[39m=\u001b[39m psd_data\u001b[39m.\u001b[39;49mgroupby(list_of_cols) \u001b[39m# Had to play around with this to get the right groupings\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/2022/Michaels_Code/grundfos-express-tools/bronze%20impeller%20removal/Multi.ipynb#ch0000022?line=28'>29</a>\u001b[0m     df_list_to_remove \u001b[39m=\u001b[39m [] \u001b[39m# will hold list of dataframes to be removed. Will concatenate to 1 dataframe later\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/2022/Michaels_Code/grundfos-express-tools/bronze%20impeller%20removal/Multi.ipynb#ch0000022?line=29'>30</a>\u001b[0m     df_list_to_keep   \u001b[39m=\u001b[39m [] \u001b[39m# will hold list of dataframes to remain in PSD. Will concatenate to 1 dataframe later\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Programs\\Python\\Python3102\\lib\\site-packages\\pandas\\core\\frame.py:7712\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/frame.py?line=7706'>7707</a>\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m   <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/frame.py?line=7708'>7709</a>\u001b[0m \u001b[39m# https://github.com/python/mypy/issues/7642\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/frame.py?line=7709'>7710</a>\u001b[0m \u001b[39m# error: Argument \"squeeze\" to \"DataFrameGroupBy\" has incompatible type\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/frame.py?line=7710'>7711</a>\u001b[0m \u001b[39m# \"Union[bool, NoDefault]\"; expected \"bool\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/frame.py?line=7711'>7712</a>\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[0;32m   <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/frame.py?line=7712'>7713</a>\u001b[0m     obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/frame.py?line=7713'>7714</a>\u001b[0m     keys\u001b[39m=\u001b[39;49mby,\n\u001b[0;32m   <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/frame.py?line=7714'>7715</a>\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/frame.py?line=7715'>7716</a>\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/frame.py?line=7716'>7717</a>\u001b[0m     as_index\u001b[39m=\u001b[39;49mas_index,\n\u001b[0;32m   <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/frame.py?line=7717'>7718</a>\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m   <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/frame.py?line=7718'>7719</a>\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[0;32m   <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/frame.py?line=7719'>7720</a>\u001b[0m     squeeze\u001b[39m=\u001b[39;49msqueeze,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/frame.py?line=7720'>7721</a>\u001b[0m     observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[0;32m   <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/frame.py?line=7721'>7722</a>\u001b[0m     dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[0;32m   <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/frame.py?line=7722'>7723</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Programs\\Python\\Python3102\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:882\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/groupby/groupby.py?line=878'>879</a>\u001b[0m \u001b[39mif\u001b[39;00m grouper \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/groupby/groupby.py?line=879'>880</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgroupby\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgrouper\u001b[39;00m \u001b[39mimport\u001b[39;00m get_grouper\n\u001b[1;32m--> <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/groupby/groupby.py?line=881'>882</a>\u001b[0m     grouper, exclusions, obj \u001b[39m=\u001b[39m get_grouper(\n\u001b[0;32m    <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/groupby/groupby.py?line=882'>883</a>\u001b[0m         obj,\n\u001b[0;32m    <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/groupby/groupby.py?line=883'>884</a>\u001b[0m         keys,\n\u001b[0;32m    <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/groupby/groupby.py?line=884'>885</a>\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m    <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/groupby/groupby.py?line=885'>886</a>\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m    <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/groupby/groupby.py?line=886'>887</a>\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/groupby/groupby.py?line=887'>888</a>\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[0;32m    <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/groupby/groupby.py?line=888'>889</a>\u001b[0m         mutated\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmutated,\n\u001b[0;32m    <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/groupby/groupby.py?line=889'>890</a>\u001b[0m         dropna\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropna,\n\u001b[0;32m    <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/groupby/groupby.py?line=890'>891</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/groupby/groupby.py?line=892'>893</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m obj\n\u001b[0;32m    <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/groupby/groupby.py?line=893'>894</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[1;32mc:\\Programs\\Python\\Python3102\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py:877\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/groupby/grouper.py?line=872'>873</a>\u001b[0m     in_axis, name, gpr \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, gpr, obj[gpr]\n\u001b[0;32m    <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/groupby/grouper.py?line=873'>874</a>\u001b[0m     \u001b[39mif\u001b[39;00m gpr\u001b[39m.\u001b[39mndim \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/groupby/grouper.py?line=874'>875</a>\u001b[0m         \u001b[39m# non-unique columns; raise here to get the name in the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/groupby/grouper.py?line=875'>876</a>\u001b[0m         \u001b[39m# exception message\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/groupby/grouper.py?line=876'>877</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGrouper for \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m not 1-dimensional\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/groupby/grouper.py?line=877'>878</a>\u001b[0m     exclusions\u001b[39m.\u001b[39madd(name)\n\u001b[0;32m    <a href='file:///c%3A/Programs/Python/Python3102/lib/site-packages/pandas/core/groupby/grouper.py?line=878'>879</a>\u001b[0m \u001b[39melif\u001b[39;00m obj\u001b[39m.\u001b[39m_is_level_reference(gpr, axis\u001b[39m=\u001b[39maxis):\n",
      "\u001b[1;31mValueError\u001b[0m: Grouper for 'Model' not 1-dimensional"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from _types._types import FilePath\n",
    "from pandas._typing import FilePath, ReadBuffer\n",
    "from typing import Union,ParamSpec,Callable\n",
    "from utils.file_ops import read_files_in_dir\n",
    "from utils.Dataframe_tools import PSD_BOM_Updates\n",
    "from pandas import DataFrame\n",
    "from openpyxl import load_workbook,worksheet,Workbook\n",
    "from openpyxl.styles.borders import Border,Side\n",
    "from openpyxl.styles import Alignment,PatternFill\n",
    "\n",
    "MYDIR= r\"C:\\Projects\\2022\\Michaels_Code\\grundfos-express-tools\\bronze impeller removal\\input files\"\n",
    "\n",
    "\n",
    "def add_removal_note():\n",
    "    timeStamp = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "    reason = input(\"Reason for removal: \")\n",
    "    authority = input(\"Who authorized/requested this change? \")\n",
    "    return timeStamp + \" \" + reason + \" per \" + authority\n",
    "\n",
    "\n",
    "def group_then_separate_by(psd_data:DataFrame,list_of_cols: list, pn_col: str, str_list:list[str])->tuple[DataFrame,DataFrame]:\n",
    "    \"\"\"list of cols are grouping categories. pn_col is the column that contains pns to find matches on.\"\"\"\n",
    "    groups = psd_data.groupby(list_of_cols) # Had to play around with this to get the right groupings\n",
    "\n",
    "    df_list_to_remove = [] # will hold list of dataframes to be removed. Will concatenate to 1 dataframe later\n",
    "    df_list_to_keep   = [] # will hold list of dataframes to remain in PSD. Will concatenate to 1 dataframe later\n",
    "\n",
    "    # Iterates through each sub-group, checking if there is a pn that meets criteria for removal\n",
    "    for _, frame in groups:\n",
    "        if any(frame[pn_col].isin(str_list)):   # Finding matching partnumbers to remove\n",
    "            df_list_to_remove.append(frame)     # Need to add this sub-group to a \"removed dataframe\"\n",
    "        else:\n",
    "            df_list_to_keep.append(frame)       # Need to retain this sub-group, add to a \"keep dataframe\"\n",
    "\n",
    "    # Concatenating list of dfs to single dfs.\n",
    "    removals = pd.concat(df_list_to_remove)\n",
    "    keep = pd.concat(df_list_to_keep)\n",
    "        \n",
    "    return removals, keep\n",
    "\n",
    "#list of sheet lists can not be empty \n",
    "\n",
    "list_sheet_lists=[['Impeller']]\n",
    "target_dir=r'C:\\Projects\\2022\\Michaels_Code\\grundfos-express-tools\\bronze impeller removal\\output files'\n",
    "\n",
    "list_of_pns = [\n",
    "    96699290, 97775274, 96699299, 97775277, 96778078,\n",
    "    97780992, 96699305, 96769184, 97778033, 96769190,\n",
    "    96769205, 97778039, 96769256, 96896891, 96769259,\n",
    "    96769271, 97780970, 96769280, 97780973\n",
    "]\n",
    "\n",
    "str_list = [str(numstr) for numstr in list_of_pns]\n",
    "\n",
    "\n",
    "def process_sheet(file: tuple[Union[FilePath, ReadBuffer[bytes], bytes],str],\n",
    "sheet_name: str | list[str],\n",
    "removal_note:str|None|bool=None,\n",
    "use_header:bool=False\n",
    ")->tuple[str,\n",
    "Union[tuple[DataFrame, int], tuple[DataFrame, DataFrame, int]],\n",
    "str,\n",
    "str]:\n",
    "    \"\"\"\n",
    "    Params:\n",
    "    data: Data comes from the binary of the file or the file path. \n",
    "    sheet_name: The name of the sheet to process.\n",
    "    removal_note: Does the sheet have its own removal note or does it share one with the entire workbook (file). The default is set to it shares a note.\"\"\"\n",
    "    #Check if sheetname is a valid sheet in the file\n",
    "    data,fname=file\n",
    "    try:\n",
    "        if not sheet_name in pd.ExcelFile(data).sheet_names:\n",
    "            raise ValueError(f\"Worksheet named '{sheet_name}' not found\")\n",
    "    except ValueError as err:\n",
    "        print(err)\n",
    "        return\n",
    "    #Need to get the header dataframe and the psd_dataframe\n",
    "    header,psd_data,length=PSD_BOM_Updates()._get_df(io=data,sheet_name=sheet_name,use_header=use_header,header=None)\n",
    "    #length = tuple of (psd_start_row,original size)\n",
    "    if not bool(removal_note):\n",
    "        removal_note=add_removal_note()\n",
    "    if header:\n",
    "        return fname,header,psd_data,length,removal_note,sheet_name\n",
    "    return fname,psd_data,length,removal_note,sheet_name\n",
    "\n",
    "    \n",
    "\n",
    "def process_file(file:FilePath,sheet_list:list[str],output_dir:str,one_removal_note:bool=False):\n",
    "    #Does this file use the same removal note for every sheet\n",
    "    if one_removal_note:\n",
    "        removal_note=add_removal_note()\n",
    "    else:\n",
    "        removal_note=None\n",
    "    if not isinstance(sheet_list,list):\n",
    "        raise Exception(f'You must give the sheets as a list to {process_file.__name__}')\n",
    "    output_file_name=os.path.join(output_dir,\"Revised \"+os.path.basename(file[1]))\n",
    "    ret=[]\n",
    "    for sheet in sheet_list:\n",
    "        val=list(process_sheet(file,sheet,removal_note))\n",
    "        val.extend([output_file_name])\n",
    "        ret.append(val)\n",
    "    return ret\n",
    "\n",
    "        \n",
    "\n",
    "def process_dir(dir,list_sheet_lists,output_dir:str,one_removal_note:bool):\n",
    "    files=read_files_in_dir(dir)\n",
    "    ret=[]\n",
    "    for i,file in enumerate(files):\n",
    "        if file[1].endswith(('.xls','.xlsx','.xlsm','.xlsb','.odf','.odt')):\n",
    "            ret.extend(process_file(file,list_sheet_lists[i],output_dir,one_removal_note))\n",
    "    return ret\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "grouping_func=(group_then_separate_by,[[\"Model\", \"Price ID\"] ,\"BOM\"],{'str_list':list_of_pns})\n",
    "\n",
    "tasks=process_dir(MYDIR,[['Impeller'],['Impeller'],['Impeller'],['Impeller'],['Impeller'],['Impeller']],target_dir,True)\n",
    "\n",
    "def add_function(tasks,function,*args,**kwargs):\n",
    "    for task in tasks:\n",
    "        task.insert(2,(function,list(args),dict(kwargs)))\n",
    "    return tasks\n",
    "\n",
    "add_function(tasks,group_then_separate_by,[\"Model\", \"Price ID\"] ,\"BOM\",str_list=list_of_pns)\n",
    "\n",
    "\n",
    "def write_new_PSD(file_name,\n",
    "psd_data,\n",
    "grouping_func:Callable[[ParamSpec.args],DataFrame],\n",
    "length:tuple[int,int],\n",
    "removal_note,\n",
    "sheet_name,\n",
    "outPut_file_path\n",
    "):\n",
    "    print(\"Opening file for updates: {}\".format(os.path.basename(file_name)))\n",
    "    psd_startrow=length[0]\n",
    "    psd_startcol=0\n",
    "    end_row = psd_data[psd_data['Full Data'] == '[END]'].index.to_list()[0]\n",
    "    psd_data = psd_data.iloc[:end_row]\n",
    "    removals, keep = grouping_func[0](psd_data,*grouping_func[1],**grouping_func[2])\n",
    "    removals.loc[removals[\"Full Data\"] == \"[START]\", \"Full Data\"] = \"\"\n",
    "    new_row = pd.DataFrame({'ID': removal_note}, index =[0])\n",
    "    removals = pd.concat([new_row, removals[:]]).reset_index()\n",
    "    column_list = keep.columns\n",
    "    removals = removals[column_list]\n",
    "    removals.sort_values(by=['ID'], inplace=True)\n",
    "    keep.loc[0,'Full Data'] = np.nan\n",
    "    keep.sort_values(by=['ID'], inplace=True)\n",
    "    keep.reset_index(drop=True, inplace=True)\n",
    "    keep.loc[0,'Full Data'] = \"[START]\"\n",
    "    num_rows = len(keep)                      \n",
    "    keep.loc[num_rows,'Full Data']=\"[END]\"\n",
    "    append_location = length[1] - len(removals)\n",
    "    after_end_row = num_rows + psd_startrow + 2\n",
    "    wb = load_workbook(file_name)\n",
    "    ws = wb[sheet_name]\n",
    "    tabName = sheet_name + \"Modified\"\n",
    "    wb.copy_worksheet(ws).title = tabName\n",
    "    ws_modified = wb[tabName]\n",
    "    ws_modified.delete_rows(after_end_row, len(removals)-1)\n",
    "    end_cell=ws.cell(row=after_end_row-1,column=1)\n",
    "    end_cell.fill=PatternFill(fill_type='solid',start_color=\"FFCC99\",end_color=\"FFCC99\")\n",
    "    for rows in ws_modified.iter_rows(min_row=append_location+2, max_row=append_location+2, min_col=1, max_col=40):\n",
    "        for cell in rows:\n",
    "            cell.fill = PatternFill(start_color=\"FF0000\", end_color=\"FF0000\", fill_type=\"solid\")\n",
    "    col=ws_modified.column_dimensions['A']\n",
    "    col.border=Border(right=Side(style='thick'))\n",
    "    wb.save(outPut_file_path)\n",
    "    del(ws,ws_modified,wb,end_cell,col)\n",
    "    with pd.ExcelWriter(outPut_file_path, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:  \n",
    "            keep.to_excel(writer, sheet_name=tabName, index=False, startrow=psd_startrow-1, startcol=psd_startcol)\n",
    "            removals.to_excel(writer, sheet_name=tabName, index=False, header=False, startrow=append_location+1, startcol=psd_startcol)\n",
    "    print(\"Closing file: {}\".format(os.path.basename(file_name)),\"\\n\",f\"Wrote file: {os.path.basename(outPut_file_path)} to {os.path.dirname(outPut_file_path)}\")\n",
    "\n",
    "for task in tasks:\n",
    "    write_new_PSD(*task)\n",
    "\n",
    "# write_new_PSD(*a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full Data</th>\n",
       "      <th>QP</th>\n",
       "      <th>ID</th>\n",
       "      <th>a</th>\n",
       "      <th>No Name 1</th>\n",
       "      <th>Model</th>\n",
       "      <th>CodeX</th>\n",
       "      <th>OptionID</th>\n",
       "      <th>Material</th>\n",
       "      <th>PACOMatlCode</th>\n",
       "      <th>...</th>\n",
       "      <th>BOM</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price ID</th>\n",
       "      <th>LeadtimeID</th>\n",
       "      <th>Days</th>\n",
       "      <th>No Name 2</th>\n",
       "      <th>No Name 3</th>\n",
       "      <th>No Name 4</th>\n",
       "      <th>No Name 5</th>\n",
       "      <th>No Name 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[START]</td>\n",
       "      <td>N</td>\n",
       "      <td>Price_BOM_L_Imp_5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:10707-LC:10707-LCV:</td>\n",
       "      <td>X0</td>\n",
       "      <td>ImpMatl_SS_AISI-304</td>\n",
       "      <td>Stainless Steel, AISI-304</td>\n",
       "      <td>H304</td>\n",
       "      <td>...</td>\n",
       "      <td>98876008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A102324</td>\n",
       "      <td>LT027</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>Price_BOM_L_Imp_11</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:10707-LC:10707-LCV:10707-LF:</td>\n",
       "      <td>X3</td>\n",
       "      <td>ImpMatl_SS_AISI-304</td>\n",
       "      <td>Stainless Steel, AISI-304</td>\n",
       "      <td>H304</td>\n",
       "      <td>...</td>\n",
       "      <td>98876012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A102326</td>\n",
       "      <td>LT027</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>Price_BOM_L_Imp_18</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:12501-LC:12501-LCV:</td>\n",
       "      <td>X0</td>\n",
       "      <td>ImpMatl_SS_AISI-304</td>\n",
       "      <td>Stainless Steel, AISI-304</td>\n",
       "      <td>H304</td>\n",
       "      <td>...</td>\n",
       "      <td>RTF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A102328</td>\n",
       "      <td>LT027</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>Price_BOM_L_Imp_25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:12507-LC:12507-LCV:</td>\n",
       "      <td>X0</td>\n",
       "      <td>ImpMatl_SS_AISI-304</td>\n",
       "      <td>Stainless Steel, AISI-304</td>\n",
       "      <td>H304</td>\n",
       "      <td>...</td>\n",
       "      <td>RTF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A102330</td>\n",
       "      <td>LT027</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>Price_BOM_L_Imp_36</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:15509-LC:15509-LCV:</td>\n",
       "      <td>X0</td>\n",
       "      <td>ImpMatl_SS_AISI-304</td>\n",
       "      <td>Stainless Steel, AISI-304</td>\n",
       "      <td>H304</td>\n",
       "      <td>...</td>\n",
       "      <td>RTF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A102333</td>\n",
       "      <td>LT027</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>Price_BOM_L_Imp_1452</td>\n",
       "      <td>1452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:30507-LC:30507-LCV:</td>\n",
       "      <td>X3</td>\n",
       "      <td>ImpMatl_NiAl-Bronze_ASTM-B148_C95400</td>\n",
       "      <td>Nickel Aluminum Bronze ASTM B148 UNS C95400</td>\n",
       "      <td>B22</td>\n",
       "      <td>...</td>\n",
       "      <td>RTF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A102236</td>\n",
       "      <td>LT250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>Price_BOM_L_Imp_1561</td>\n",
       "      <td>1561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:30507-LC:30507-LCV:</td>\n",
       "      <td>X3</td>\n",
       "      <td>ImpMatl_SS_AISI-304</td>\n",
       "      <td>Stainless Steel, AISI-304</td>\n",
       "      <td>H304</td>\n",
       "      <td>...</td>\n",
       "      <td>99837749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A102375</td>\n",
       "      <td>LT250</td>\n",
       "      <td>126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>Price_BOM_L_Imp_1746</td>\n",
       "      <td>1746</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:30507-LC:30507-LCV:</td>\n",
       "      <td>X3</td>\n",
       "      <td>ImpMatl_NiAl-Bronze_ASTM-B148_C95400</td>\n",
       "      <td>Nickel Aluminum Bronze ASTM B148 UNS C95400</td>\n",
       "      <td>B22</td>\n",
       "      <td>...</td>\n",
       "      <td>RTF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A102236</td>\n",
       "      <td>LT250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>Price_BOM_L_Imp_1855</td>\n",
       "      <td>1855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:30507-LC:30507-LCV:</td>\n",
       "      <td>X3</td>\n",
       "      <td>ImpMatl_SS_AISI-304</td>\n",
       "      <td>Stainless Steel, AISI-304</td>\n",
       "      <td>H304</td>\n",
       "      <td>...</td>\n",
       "      <td>RTF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A101852</td>\n",
       "      <td>LT250</td>\n",
       "      <td>126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>[END]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>753 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Full Data   QP                    ID     a  No Name 1  \\\n",
       "0     [START]    N     Price_BOM_L_Imp_5     5        NaN   \n",
       "1         NaN    N    Price_BOM_L_Imp_11    11        NaN   \n",
       "2         NaN    N    Price_BOM_L_Imp_18    18        NaN   \n",
       "3         NaN    N    Price_BOM_L_Imp_25    25        NaN   \n",
       "4         NaN    N    Price_BOM_L_Imp_36    36        NaN   \n",
       "..        ...  ...                   ...   ...        ...   \n",
       "748       NaN    N  Price_BOM_L_Imp_1452  1452        NaN   \n",
       "749       NaN    N  Price_BOM_L_Imp_1561  1561        NaN   \n",
       "750       NaN    N  Price_BOM_L_Imp_1746  1746        NaN   \n",
       "751       NaN    N  Price_BOM_L_Imp_1855  1855        NaN   \n",
       "752     [END]  NaN                   NaN   NaN        NaN   \n",
       "\n",
       "                             Model CodeX  \\\n",
       "0             :10707-LC:10707-LCV:    X0   \n",
       "1    :10707-LC:10707-LCV:10707-LF:    X3   \n",
       "2             :12501-LC:12501-LCV:    X0   \n",
       "3             :12507-LC:12507-LCV:    X0   \n",
       "4             :15509-LC:15509-LCV:    X0   \n",
       "..                             ...   ...   \n",
       "748           :30507-LC:30507-LCV:    X3   \n",
       "749           :30507-LC:30507-LCV:    X3   \n",
       "750           :30507-LC:30507-LCV:    X3   \n",
       "751           :30507-LC:30507-LCV:    X3   \n",
       "752                            NaN   NaN   \n",
       "\n",
       "                                 OptionID  \\\n",
       "0                     ImpMatl_SS_AISI-304   \n",
       "1                     ImpMatl_SS_AISI-304   \n",
       "2                     ImpMatl_SS_AISI-304   \n",
       "3                     ImpMatl_SS_AISI-304   \n",
       "4                     ImpMatl_SS_AISI-304   \n",
       "..                                    ...   \n",
       "748  ImpMatl_NiAl-Bronze_ASTM-B148_C95400   \n",
       "749                   ImpMatl_SS_AISI-304   \n",
       "750  ImpMatl_NiAl-Bronze_ASTM-B148_C95400   \n",
       "751                   ImpMatl_SS_AISI-304   \n",
       "752                                   NaN   \n",
       "\n",
       "                                        Material PACOMatlCode  ...       BOM  \\\n",
       "0                      Stainless Steel, AISI-304         H304  ...  98876008   \n",
       "1                      Stainless Steel, AISI-304         H304  ...  98876012   \n",
       "2                      Stainless Steel, AISI-304         H304  ...       RTF   \n",
       "3                      Stainless Steel, AISI-304         H304  ...       RTF   \n",
       "4                      Stainless Steel, AISI-304         H304  ...       RTF   \n",
       "..                                           ...          ...  ...       ...   \n",
       "748  Nickel Aluminum Bronze ASTM B148 UNS C95400          B22  ...       RTF   \n",
       "749                    Stainless Steel, AISI-304         H304  ...  99837749   \n",
       "750  Nickel Aluminum Bronze ASTM B148 UNS C95400          B22  ...       RTF   \n",
       "751                    Stainless Steel, AISI-304         H304  ...       RTF   \n",
       "752                                          NaN          NaN  ...       NaN   \n",
       "\n",
       "    Description Price ID LeadtimeID Days No Name 2 No Name 3 No Name 4  \\\n",
       "0           NaN  A102324      LT027    0       NaN       NaN       NaN   \n",
       "1           NaN  A102326      LT027    0       NaN       NaN       NaN   \n",
       "2           NaN  A102328      LT027    0       NaN       NaN       NaN   \n",
       "3           NaN  A102330      LT027    0       NaN       NaN       NaN   \n",
       "4           NaN  A102333      LT027    0       NaN       NaN       NaN   \n",
       "..          ...      ...        ...  ...       ...       ...       ...   \n",
       "748         NaN  A102236      LT250  NaN       NaN       NaN       NaN   \n",
       "749         NaN  A102375      LT250  126       NaN       NaN       NaN   \n",
       "750         NaN  A102236      LT250  NaN       NaN       NaN       NaN   \n",
       "751         NaN  A101852      LT250  126       NaN       NaN       NaN   \n",
       "752         NaN      NaN        NaN  NaN       NaN       NaN       NaN   \n",
       "\n",
       "    No Name 5  No Name 6  \n",
       "0         NaN        NaN  \n",
       "1         NaN        NaN  \n",
       "2         NaN        NaN  \n",
       "3         NaN        NaN  \n",
       "4         NaN        NaN  \n",
       "..        ...        ...  \n",
       "748       NaN        NaN  \n",
       "749       NaN        NaN  \n",
       "750       NaN        NaN  \n",
       "751       NaN        NaN  \n",
       "752       NaN        NaN  \n",
       "\n",
       "[753 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psd_data_1=tasks[0][1]\n",
    "\n",
    "psd_data_1.iloc[:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def name_blank_cols(df):\n",
    "    col=df.columns.to_list()\n",
    "    count=1\n",
    "    for i,item in enumerate(col.copy()):\n",
    "        if str(item)=='nan':\n",
    "            col[i]=f\"No Name {count}\"\n",
    "            count+=1\n",
    "    df.columns=col\n",
    "    \n",
    "\n",
    "name_blank_cols(psd_data_1)\n",
    "psd_data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.file_ops import get_files_in_dir\n",
    "sheet_list=[]\n",
    "sheet='Impeller'\n",
    "for file in get_files_in_dir(MYDIR,('.xlsx')):\n",
    "    sheet_list.append([sheet])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a New File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from _utils.excel_tools import write_excel_file\n",
    "from _utils.file_ops import add_str_to_filename\n",
    "from _utils.Dataframe_tools import write_df_to_excel\n",
    "\n",
    "header=process_sheet(file,'Impeller','No')\n",
    "tabName = sheetname + \" No Bronze\"\n",
    "\n",
    "\n",
    "with pd.ExcelWriter(outputPath, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:\n",
    "        keep.to_excel(writer, sheet_name=tabName, index=False,startrow=psd_startrow-1,startcol=psd_startcol)\n",
    "        removals.to_excel(writer, sheet_name=tabName, index=False,header=False, startrow=append_location+1, startcol=psd_startcol)\n",
    "        header.to_excel(writer, sheet_name=tabName, index=False,header=False, startrow=0, startcol=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl.styles.borders import Border,Side\n",
    "from openpyxl.styles.fonts import Font\n",
    "from openpyxl.styles import Alignment,PatternFill\n",
    "from openpyxl import load_workbook,worksheet,Workbook\n",
    "from openpyxl.worksheet import cell_range\n",
    "\n",
    "\n",
    "outputPath=r'C:\\Projects\\2022\\Michaels_Code\\grundfos-express-tools\\bronze impeller removal\\output files\\Revised Lbom-ES.xlsx'\n",
    "sheetname='Impeller'\n",
    "tabName = sheetname + \" No Bronze\"\n",
    "psd_startrow=get_start_row(wb,'Impeller',min_row=1,max_col=1)\n",
    "\n",
    "\n",
    "wb=load_workbook(outputPath)\n",
    "ws=wb[tabName]\n",
    "\n",
    "#Adding the Border\n",
    "col=ws.column_dimensions['A']\n",
    "col.border=Border(right=Side(style='thick'))\n",
    "\n",
    "#Fitting the Cell Widths in the Columns\n",
    "dims = {}\n",
    "for row in ws.iter_rows(min_row=0):\n",
    "    for cell in row:\n",
    "        if cell.value:\n",
    "            dims[cell.column_letter] = max((dims.get(cell.column_letter, 0)+2, len(str(cell.value))+2))\n",
    "            if row[0].row <= psd_startrow and cell.column_letter=='A':\n",
    "                cell.border=Border(right=Side(style='thick'))\n",
    "            elif cell.row<psd_startrow and cell.value=='[END]': #Gets the column end\n",
    "                cell.fill=PatternFill(fill_type='solid',start_color=\"FFCC99\",end_color=\"FFCC99\")\n",
    "\n",
    "                #Applying Top Rows Formatting\n",
    "                for row2 in ws.iter_rows(min_col=0,max_col=cell.column-1,min_row=0,max_row=psd_startrow-1):\n",
    "                    for cell2 in row2:\n",
    "                        if cell2.row==1:\n",
    "                            cell2.fill=PatternFill(fill_type='solid',start_color=\"808080\",end_color=\"808080\")\n",
    "                            cell2.font=Font(color='00FFFFFF')\n",
    "                            if cell2.column==1:\n",
    "                                cell2.font=Font(bold=True,color='00FFFFFF')\n",
    "                                cell2.border=Border(right=Side(style='thick'),bottom=Side(style='thick'))\n",
    "                            else:\n",
    "                                cell2.border=Border(bottom=Side(style='thick'))\n",
    "                        elif cell2.row==cell.row-1:\n",
    "                            cell2.fill=PatternFill(fill_type='solid',start_color=\"FFCC99\",end_color=\"FFCC99\")\n",
    "                            if cell2.column==1:\n",
    "                                cell2.border=Border(right=Side(style='thick'),bottom=Side(style='thin'))\n",
    "                            else:\n",
    "                                cell2.border=Border(bottom=Side(style='thin'))\n",
    "                        elif cell2.row==psd_startrow-1:\n",
    "                            cell2.fill=PatternFill(fill_type='solid',start_color=\"FFCC99\",end_color=\"FFCC99\")\n",
    "                            if cell2.column==1:\n",
    "                                cell2.border=Border(right=Side(style='thick'),bottom=Side(style='thick'))\n",
    "                            else:\n",
    "                                cell2.border=Border(bottom=Side(style='thick'))\n",
    "                        else:\n",
    "                            cell2.fill=PatternFill(fill_type='solid',start_color=\"FFCC99\",end_color=\"FFCC99\")\n",
    "                        if cell2.column>1:\n",
    "                            cell2.alignment=Alignment(horizontal='center')\n",
    "                        else:\n",
    "                            cell2.alignment=Alignment(horizontal='left')\n",
    "                flt=str(cell_range.CellRange(min_col=2, min_row=psd_startrow, max_col=cell.column-1, max_row=psd_startrow))\n",
    "                ws.auto_filter.ref=flt     \n",
    "            elif cell.row>psd_startrow and cell.column==1 and cell.value=='[START]':\n",
    "                cell.fill=PatternFill(fill_type='solid',start_color=\"FFCC99\",end_color=\"FFCC99\")\n",
    "                cell.alignment=Alignment(horizontal='right')\n",
    "            \n",
    "            elif cell.value=='[END]' and cell.row>psd_startrow and cell.column==1:\n",
    "                cell.fill=PatternFill(fill_type='solid',start_color=\"FFCC99\",end_color=\"FFCC99\")\n",
    "            \n",
    "            elif cell.row==append_location+2 and cell.column>=1 and cell.column<=40:\n",
    "                cell.fill = PatternFill(start_color=\"FF0000\", end_color=\"FF0000\", fill_type=\"solid\")\n",
    "                                   \n",
    "for col, value in dims.items():\n",
    "    ws.column_dimensions[col].width = value\n",
    "\n",
    "\n",
    "wb.save(outputPath)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- it is faster to just use the copy code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "path=r'C:\\Projects\\2022\\Michaels_Code\\grundfos-express-tools\\bronze impeller removal\\input files'\n",
    "types=[]\n",
    "pd.read_excel\n",
    "glob.glob(path+'\\*.*')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d89935b22884bac8e846ef6a5fb14ff565b7e382ac92ebe1031401d4b8e3f29"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
